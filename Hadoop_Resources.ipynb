{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop Training Resources\n",
    "\n",
    "### Online Courses\n",
    "\n",
    "+ [Big Data and Hadoop for Beginners - with Hands-on!](https://www.udemy.com/big-data-and-hadoop-for-beginners/)\n",
    "    - 3h effort (paid)\n",
    "    - Hands-on - beginner level\n",
    "    - Requirement: SQL and RDBMS \n",
    "    - Focus: architecture (**MapReduce, YARN, Hive, Pig**) + own code with Hive/Pig to process data\n",
    "    - Extras: design data pipeline with Pig/Hive\n",
    "\n",
    "\n",
    "+ [Learn Big Data: The Hadoop Ecosystem Masterclass](https://www.udemy.com/learn-big-data-the-hadoop-ecosystem-masterclass/)\n",
    "\n",
    "    - 6h effort (paid) \n",
    "    - Mix hands-on and theory\n",
    "    - Goal: process big data using batch + Hadoop Stack + use realtime data\n",
    "    - Requirement: Programming language advantageous + run virtual server (8Mb+ RAM)\n",
    "    - Focus: architecture big data + some hands-on\n",
    "    - Extras: install/config Hortonworks Data Platform\n",
    "\n",
    "\n",
    "+ [The Ultimate Hands-On Hadoop - Tame your Big Data!](https://www.udemy.com/the-ultimate-hands-on-hadoop-tame-your-big-data)\n",
    "\n",
    "    - 14.5h effort (paid)\n",
    "    - Ultimate serious course\n",
    "    - Goal: design distributed systems with Hadoop \n",
    "        + use Pig/Spark scripts for data processing in cluster \n",
    "        + Analyse non-relational data (**HBase, Cassandra, MongoDB**) \n",
    "        + Analyse relational data (**Hive/MySQL**)\n",
    "        + Choice of storage tech \n",
    "        + Publish data to Hadoop cluster (**Kafka, Sqoop, Flume**)  \n",
    "    - Focus: 25+ technologies with knowledge BigData\n",
    "\n",
    "#### Other Courses:  \n",
    " + [Cognitive class: Hadoop 101](https://cognitiveclass.ai/courses/introduction-to-hadoop/) part of Big Data [Learning Path - Certification](https://cognitiveclass.ai/learn/big-data/) and [Hadoop Fundamentals](https://cognitiveclass.ai/learn/hadoop/)\n",
    " \n",
    "     - 5h effort (free + IBM certification)\n",
    "     - Requirement: [Big Data concepts](https://cognitiveclass.ai/courses/what-is-big-data/)\n",
    "     - Goal: \n",
    "         + Hadoop architecture/components (e.g. MapReduce, HDFS)\n",
    "         + Add/remove nodes from cluster\n",
    "         + Config parameters\n",
    "         + Other ecosystem components (Pig, Hive, HBase, ZooKeeper, Oozie, Sqoop, Flume)\n",
    "         \n",
    "+ [Eureka: Big Data Hadoop](https://www.youtube.com/playlist?list=PL9ooVrP1hQOFrYxqxb0NJCdCABPZNo0pD)\n",
    "    - All online youtube\n",
    "    \n",
    "Other resources: \n",
    " + [5 courses Hadoop](https://hackernoon.com/top-5-hadoop-courses-for-big-data-professionals-best-of-lot-7998f593d138) \n",
    " + [5 Big Data Courses](https://www.kdnuggets.com/2016/08/simplilearn-5-big-data-courses.html)\n",
    " + [Best Big Data Analytics Online courses](https://www.bigdatanews.datasciencecentral.com/profiles/blogs/10-best-big-data-analytics-courses-online) \n",
    " \n",
    "\n",
    "    \n",
    " \n",
    " \n",
    "## Certifications: \n",
    " \n",
    " + Cognitive AI [Learning Path - Certification](https://cognitiveclass.ai/learn/big-data/)\n",
    " + MS [Big Data Track](https://academy.microsoft.com/en-us/professional-program/tracks/big-data/)\n",
    " + Cloudera [CDH](https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html)\n",
    " + Cloudera Certified Professional [CCP and CCA](https://www.cloudera.com/about/training/certification.html)\n",
    "     - Preparation training [Hadoop Developer](https://www.udemy.com/hadoop-tutorial/)<br>     \n",
    " + Hortonworks [Hadoop Developer](https://hortonworks.com/services/training/certification/)\n",
    "     - Preparation training available     \n",
    " + Coursera [Hadoop Platform and Application Framework](https://www.coursera.org/learn/hadoop)\n",
    "     - Part of [Big Data Specialisation](https://www.coursera.org/specializations/big-data?action=enroll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop Books:\n",
    "+ [List Hadoop Books](https://data-flair.training/blogs/hadoop-books/)\n",
    "+ [List Free Books Hadoop](https://www.datasciencecentral.com/profiles/blogs/free-ebooks-on-hadoop-deep-learning-and-dataviz-by-packt)\n",
    "+ [Hadoop illuminated](https://www.tutorialspoint.com/hadoop/hadoop_useful_resources.htm)\n",
    "+ [Online Hadoop Book](http://hadoopilluminated.com/index.html)\n",
    "\n",
    "\n",
    "### Hadoop Documentation: \n",
    "+ [Official documentation](http://hadoop.apache.org/docs/current/)\n",
    "\n",
    "### Hadoop Tutorials:\n",
    "+ [Data Flair Hadoop](https://data-flair.training/blogs/installation-of-hadoop-3-x-on-ubuntu/)\n",
    "+ [Free Hadoop Tutorials](https://www.datasciencecentral.com/profiles/blogs/hadoop-tutorials)\n",
    "+ [Hadoop,Spark and MapReduce Articles](https://www.datasciencecentral.com/profiles/blogs/11-great-hadoop-spark-and-map-reduce-articles)\n",
    "\n",
    "### Data sources: \n",
    "+ [Free Data Sources](https://www.octoparse.com/blog/big-data-70-amazing-free-data-sources-you-should-know-for-2017)\n",
    "\n",
    "\n",
    "### Resourceful sites: \n",
    "+ [Big Data Websites](https://www.datasciencecentral.com/profiles/blogs/my-top-websites-for-big-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Best Data Science Books](https://www.bigdatanews.datasciencecentral.com/profiles/blogs/80-best-data-science-books-that-are-worthy-reading)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
